# Multi-layer, g(a) = tanh(a), no regularization, no momentum.
layer_specs: [784, 128, 10]
activation: "tanh"
learning_rate: 0.001
batch_size: 128
epochs: 100
early_stop: True
early_stop_epoch: 5
L1_penalty: 0
L2_penalty: 0
momentum: False
momentum_gamma: 0.9